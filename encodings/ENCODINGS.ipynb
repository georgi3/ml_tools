{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Exploring Different Styles of Categorical Encoding\n",
    "- https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from tools.supporting_scripts import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "fname = '../data/clients.csv'\n",
    "df = pd.read_csv(fname)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "label_enc = LabelEncoder()\n",
    "knn = KNNImputer(n_neighbors=3)\n",
    "\n",
    "df = pd.read_csv(fname)\n",
    "df.loc[:, 'loan_approval'] = label_enc.fit_transform(df['loan_approval'])\n",
    "y = df['loan_approval']\n",
    "df.drop(['id', 'loan_approval'], axis=1, inplace=True)\n",
    "df = cast_spouse_income(df)\n",
    "df = df.replace({'credit_history': {1.0: 'Yes', 0.0: 'No'}})\n",
    "df.loc[:, 'monthly_payment'] = df.astype({'monthly_payment': 'object'})\n",
    "num_feats = df.columns[df.dtypes != 'object'].tolist()\n",
    "df_cat = df.loc[:, df.dtypes=='object'].copy()\n",
    "df_num = df.loc[:, num_feats].copy()\n",
    "df_cat.fillna(value='MISSING', axis=0, inplace=True)\n",
    "df_num_transformed = knn.fit_transform(df_num)\n",
    "df_num = pd.DataFrame(df_num_transformed, columns=num_feats)\n",
    "df_num['income/loan'] = df_num['income'] / (df_num['loan_in_thousands'] * 1000)\n",
    "df_num['income'] = df_num['income'] + df_num['spouse_income']\n",
    "df_num.drop(['spouse_income'], axis=1, inplace=True)\n",
    "df = pd.concat([df_num, df_cat, y], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "     income  loan_in_thousands  income/loan     sex married dependents  \\\n0    5849.0              138.0     0.042384    Male      No          0   \n1    6091.0              128.0     0.035805    Male     Yes          1   \n2    3000.0               66.0     0.045455    Male     Yes          0   \n3    4941.0              120.0     0.021525    Male     Yes          0   \n4    6000.0              141.0     0.042553    Male      No          0   \n..      ...                ...          ...     ...     ...        ...   \n609  2900.0               71.0     0.040845  Female      No          0   \n610  4106.0               40.0     0.102650    Male     Yes         3+   \n611  8312.0              253.0     0.031905    Male     Yes          1   \n612  7583.0              187.0     0.040551    Male     Yes          2   \n613  4583.0              133.0     0.034459  Female      No          0   \n\n        education working monthly_payment credit_history property_type  \\\n0        Graduate      No           360.0            Yes         Urban   \n1        Graduate      No           360.0            Yes         Rural   \n2        Graduate     Yes           360.0            Yes         Urban   \n3    Not Graduate      No           360.0            Yes         Urban   \n4        Graduate      No           360.0            Yes         Urban   \n..            ...     ...             ...            ...           ...   \n609      Graduate      No           360.0            Yes         Rural   \n610      Graduate      No           180.0            Yes         Rural   \n611      Graduate      No           360.0            Yes         Urban   \n612      Graduate      No           360.0            Yes         Urban   \n613      Graduate     Yes           360.0             No     Semiurban   \n\n     loan_approval  \n0                1  \n1                0  \n2                1  \n3                1  \n4                1  \n..             ...  \n609              1  \n610              1  \n611              1  \n612              1  \n613              0  \n\n[614 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>income</th>\n      <th>loan_in_thousands</th>\n      <th>income/loan</th>\n      <th>sex</th>\n      <th>married</th>\n      <th>dependents</th>\n      <th>education</th>\n      <th>working</th>\n      <th>monthly_payment</th>\n      <th>credit_history</th>\n      <th>property_type</th>\n      <th>loan_approval</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5849.0</td>\n      <td>138.0</td>\n      <td>0.042384</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>360.0</td>\n      <td>Yes</td>\n      <td>Urban</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6091.0</td>\n      <td>128.0</td>\n      <td>0.035805</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>360.0</td>\n      <td>Yes</td>\n      <td>Rural</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3000.0</td>\n      <td>66.0</td>\n      <td>0.045455</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>Yes</td>\n      <td>360.0</td>\n      <td>Yes</td>\n      <td>Urban</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4941.0</td>\n      <td>120.0</td>\n      <td>0.021525</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Not Graduate</td>\n      <td>No</td>\n      <td>360.0</td>\n      <td>Yes</td>\n      <td>Urban</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6000.0</td>\n      <td>141.0</td>\n      <td>0.042553</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>360.0</td>\n      <td>Yes</td>\n      <td>Urban</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>609</th>\n      <td>2900.0</td>\n      <td>71.0</td>\n      <td>0.040845</td>\n      <td>Female</td>\n      <td>No</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>360.0</td>\n      <td>Yes</td>\n      <td>Rural</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>610</th>\n      <td>4106.0</td>\n      <td>40.0</td>\n      <td>0.102650</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>3+</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>180.0</td>\n      <td>Yes</td>\n      <td>Rural</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>611</th>\n      <td>8312.0</td>\n      <td>253.0</td>\n      <td>0.031905</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>360.0</td>\n      <td>Yes</td>\n      <td>Urban</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>612</th>\n      <td>7583.0</td>\n      <td>187.0</td>\n      <td>0.040551</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>2</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>360.0</td>\n      <td>Yes</td>\n      <td>Urban</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>613</th>\n      <td>4583.0</td>\n      <td>133.0</td>\n      <td>0.034459</td>\n      <td>Female</td>\n      <td>No</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>Yes</td>\n      <td>360.0</td>\n      <td>No</td>\n      <td>Semiurban</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>614 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Frequency Encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "freq = df.groupby('sex').size() / len(df)\n",
    "df.loc[:, 'sex'] = df['sex'].map(freq)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "0    0.796417\n1    0.796417\n2    0.796417\n3    0.796417\n4    0.796417\n5    0.796417\nName: sex, dtype: float64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:5, 'sex']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Mean Encoding or Target Encoding\n",
    "* does not affect the volume of the data\n",
    "* helps in faster learning\n",
    "* NOTE: notorious for over-fitting, to be used with regularization and cross-validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dependents\n",
      "0          0.689855\n",
      "1          0.647059\n",
      "2          0.752475\n",
      "3+         0.647059\n",
      "MISSING    0.600000\n",
      "Name: loan_approval, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mean_encode = df.groupby('dependents')['loan_approval'].mean()\n",
    "print(mean_encode)\n",
    "df.loc[:, 'dependents'] = df['dependents'].map(mean_encode)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "0    0.689855\n1    0.647059\n2    0.689855\n3    0.689855\n4    0.689855\n5    0.752475\nName: dependents, dtype: float64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:5, 'dependents']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dependents\n",
      "0.600000    0.675910\n",
      "0.647059    0.662963\n",
      "0.689855    0.689280\n",
      "0.752475    0.720048\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# another variation of target encoding using smoothing\n",
    "mean = df['loan_approval'].mean()\n",
    "agg = df.groupby('dependents')['loan_approval'].agg(['count', 'mean'])\n",
    "counts = agg['count']\n",
    "means = agg['mean']\n",
    "weight = 100\n",
    "# compute smoothed means\n",
    "smooth = (counts * means + weight * mean) / (counts + weight)\n",
    "print(smooth)\n",
    "df.loc[:, 'dependents'] = df['dependents'].map(smooth)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "0    0.689280\n1    0.662963\n2    0.689280\n3    0.689280\n4    0.689280\n5    0.720048\nName: dependents, dtype: float64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:5, 'dependents']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Weight of Evidence Encoding (Woe)\n",
    "##### https://towardsdatascience.com/attribute-relevance-analysis-in-python-iv-and-woe-b5651443fc04\n",
    "##### https://www.listendata.com/2015/03/weight-of-evidence-woe-and-information.html\n",
    "##### see also IV (Information Value)\n",
    "* measures strength of grouping technique to separate good from bad\n",
    "* primarily developed for loan evaluation\n",
    "* WoE = (ln(distr good / distr bad)) * 100 NOTE: WoE will be 0 if the P(Goods) / P(Bads) = 1, If P(Bads) > P(Goods) the odds ratio will be < 1 and the WoE will be < 0; if, on the other hand, P(Goods) > P(Bads) in a group, then WoE > 0\n",
    "* Well suited for Logistic Regression (binary classification)\n",
    "#### Advantages\n",
    "1. It can transform an independent variable to establish a monotonic relationship to the dependent variable. It does more than this — to secure a monotonic relationship it would be enough to “recode” it to any ordered measure (for example 1,2,3,4…), but the WoE transformation orders the categories on a “logistic” scale which is natural for Logistic Regression\n",
    "2. For variables with too many (sparsely populated) discrete values, these can be grouped into categories (densely populated), and the WoE can be used to express information for the whole category\n",
    "3. The (univariate) effect of each category on the dependent variable can be compared across categories and variables because WoE is a standardized value (for example, you can compare WoE of married people to WoE of manual workers)\n",
    "#### Caveats\n",
    "1. Loss of information (variation) due to binning to a few categories\n",
    "2. It is a “univariate” measure, so it does not take into account the correlation between independent variables\n",
    "3. It is easy to manipulate (over-fit) the effect of variables according to how categories are created\n",
    "#### Prerequisites\n",
    "1. Data must be clean (nan could be substituted with \"MISSING\" to see how it affects target as well\n",
    "2. There should not be any continuous features (use qcut)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# WoE = (ln(Relative Frequency of Good / Relative Frequency of Bad)) * 100\n",
    "# IV = Σ(DistributedGood_i - DistributedBad_i) * WoE_i"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "num_feats = ['income', 'spouse_income', 'loan_in_thousands', 'monthly_payment']\n",
    "CONTINUOUS = ['income', 'loan_in_thousands', 'income/loan']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def calculate_woe_iv(dataset, feature, target):\n",
    "    lst = []\n",
    "    for i in range(dataset[feature].nunique()):\n",
    "        val = list(dataset[feature].unique())[i]\n",
    "        lst.append({\n",
    "            'Value': val,\n",
    "            'All': dataset[dataset[feature] == val].count()[feature],\n",
    "            'Good': dataset[(dataset[feature] == val) & (dataset[target] == 1)].count()[feature],\n",
    "            'Bad': dataset[(dataset[feature] == val) & (dataset[target] == 0)].count()[feature]\n",
    "        })\n",
    "\n",
    "    dset = pd.DataFrame(lst)\n",
    "    dset['Distr_Good'] = dset['Good'] / dset['Good'].sum()\n",
    "    dset['Distr_Bad'] = dset['Bad'] / dset['Bad'].sum()\n",
    "    np.seterr(divide='ignore')                                  # lifting-up the warning because it is handled below\n",
    "    dset['WoE'] = np.log(dset['Distr_Good'] / dset['Distr_Bad'])\n",
    "    np.seterr(divide='warn')\n",
    "    dset = dset.replace({'WoE': {np.inf: 0, -np.inf: 0}})\n",
    "    dset['IV'] = (dset['Distr_Good'] - dset['Distr_Bad']) * dset['WoE']\n",
    "    iv = dset['IV'].sum()\n",
    "\n",
    "    dset = dset.sort_values(by='WoE')\n",
    "\n",
    "    return dset, iv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "target = 'loan_approval'\n",
    "df_train = df.copy(deep=True)\n",
    "# df_train['income'] = pd.qcut(df_train['income'], 20)\n",
    "# calculate_woe_iv(df_train, 'income', target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WoE and IV for income:\n",
      "      Value  All  Good  Bad  Distr_Good  Distr_Bad       WoE        IV\n",
      "133  4583.0    4     1    3    0.002370   0.015625 -1.886122  0.025001\n",
      "43   6277.0    3     1    2    0.002370   0.010417 -1.480657  0.011915\n",
      "208  5000.0    3     1    2    0.002370   0.010417 -1.480657  0.011915\n",
      "64   4166.0    3     1    2    0.002370   0.010417 -1.480657  0.011915\n",
      "181  4885.0    2     1    1    0.002370   0.005208 -0.787510  0.002235\n",
      "..      ...  ...   ...  ...         ...        ...       ...       ...\n",
      "197  6506.0    1     1    0    0.002370   0.000000  0.000000  0.000000\n",
      "191  5100.0    1     1    0    0.002370   0.000000  0.000000  0.000000\n",
      "71   3750.0    4     3    1    0.007109   0.005208  0.311102  0.000591\n",
      "312  2500.0    4     3    1    0.007109   0.005208  0.311102  0.000591\n",
      "4    6000.0    5     4    1    0.009479   0.005208  0.598784  0.002557\n",
      "\n",
      "[554 rows x 8 columns]\n",
      "IV score is : 0.10034147531267246\n",
      "\n",
      "    \n",
      "WoE and IV for loan_in_thousands:\n",
      "     Value  All  Good  Bad  Distr_Good  Distr_Bad       WoE        IV\n",
      "36    80.0    6     2    4    0.004739   0.020833 -1.480657  0.023830\n",
      "163  103.0    3     1    2    0.002370   0.010417 -1.480657  0.011915\n",
      "153  173.0    3     1    2    0.002370   0.010417 -1.480657  0.011915\n",
      "113  170.0    3     1    2    0.002370   0.010417 -1.480657  0.011915\n",
      "106   67.0    3     1    2    0.002370   0.010417 -1.480657  0.011915\n",
      "..     ...  ...   ...  ...         ...        ...       ...       ...\n",
      "66   175.0    6     5    1    0.011848   0.005208  0.821928  0.005458\n",
      "115   90.0    6     5    1    0.011848   0.005208  0.821928  0.005458\n",
      "3    120.0   20    17    3    0.040284   0.015625  0.947091  0.023355\n",
      "15   125.0    7     6    1    0.014218   0.005208  1.004250  0.009048\n",
      "19   115.0    8     7    1    0.016588   0.005208  1.158400  0.013182\n",
      "\n",
      "[216 rows x 8 columns]\n",
      "IV score is : 0.29026292835605977\n",
      "\n",
      "    \n",
      "WoE and IV for income/loan:\n",
      "        Value  All  Good  Bad  Distr_Good  Distr_Bad      WoE        IV\n",
      "158  0.024833    2     1    1     0.00237   0.005208 -0.78751  0.002235\n",
      "0    0.042384    1     1    0     0.00237   0.000000  0.00000  0.000000\n",
      "401  0.038356    1     0    1     0.00000   0.005208  0.00000 -0.000000\n",
      "402  0.039539    1     1    0     0.00237   0.000000  0.00000  0.000000\n",
      "403  0.018843    1     1    0     0.00237   0.000000  0.00000  0.000000\n",
      "..        ...  ...   ...  ...         ...        ...      ...       ...\n",
      "204  0.031589    1     1    0     0.00237   0.000000  0.00000  0.000000\n",
      "205  0.036733    1     1    0     0.00237   0.000000  0.00000  0.000000\n",
      "206  0.040550    1     1    0     0.00237   0.000000  0.00000  0.000000\n",
      "208  0.042017    1     1    0     0.00237   0.000000  0.00000  0.000000\n",
      "607  0.034459    1     0    1     0.00000   0.005208  0.00000 -0.000000\n",
      "\n",
      "[608 rows x 8 columns]\n",
      "IV score is : 0.0022354769779558267\n",
      "\n",
      "    \n",
      "WoE and IV for sex:\n",
      "      Value  All  Good  Bad  Distr_Good  Distr_Bad       WoE        IV\n",
      "2  0.021173   13     8    5    0.018957   0.026042 -0.317506  0.002249\n",
      "1  0.182410  112    75   37    0.177725   0.192708 -0.080940  0.001213\n",
      "0  0.796417  489   339  150    0.803318   0.781250  0.027855  0.000615\n",
      "IV score is : 0.004076742435353663\n",
      "\n",
      "    \n",
      "WoE and IV for married:\n",
      "     Value  All  Good  Bad  Distr_Good  Distr_Bad       WoE        IV\n",
      "0       No  213   134   79    0.317536   0.411458 -0.259118  0.024337\n",
      "2  MISSING    3     3    0    0.007109   0.000000  0.000000  0.000000\n",
      "1      Yes  398   285  113    0.675355   0.588542  0.137591  0.011945\n",
      "IV score is : 0.03628191626470459\n",
      "\n",
      "    \n",
      "WoE and IV for dependents:\n",
      "      Value  All  Good  Bad  Distr_Good  Distr_Bad       WoE        IV\n",
      "3  0.675910   15     9    6    0.021327   0.031250 -0.382045  0.003791\n",
      "1  0.662963  153    99   54    0.234597   0.281250 -0.181374  0.008462\n",
      "0  0.689280  345   238  107    0.563981   0.557292  0.011932  0.000080\n",
      "2  0.720048  101    76   25    0.180095   0.130208  0.324348  0.016181\n",
      "IV score is : 0.028513011820656978\n",
      "\n",
      "    \n",
      "WoE and IV for education:\n",
      "          Value  All  Good  Bad  Distr_Good  Distr_Bad       WoE        IV\n",
      "1  Not Graduate  134    82   52    0.194313   0.270833 -0.332034  0.025407\n",
      "0      Graduate  480   340  140    0.805687   0.729167  0.099793  0.007636\n",
      "IV score is : 0.033043684972009234\n",
      "\n",
      "    \n",
      "WoE and IV for working:\n",
      "     Value  All  Good  Bad  Distr_Good  Distr_Bad       WoE        IV\n",
      "1      Yes   82    56   26    0.132701   0.135417 -0.020255  0.000055\n",
      "0       No  500   343  157    0.812796   0.817708 -0.006025  0.000030\n",
      "2  MISSING   32    23    9    0.054502   0.046875  0.150760  0.001150\n",
      "IV score is : 0.0012344936760713692\n",
      "\n",
      "    \n",
      "WoE and IV for monthly_payment:\n",
      "      Value  All  Good  Bad  Distr_Good  Distr_Bad       WoE        IV\n",
      "7     480.0   15     6    9    0.014218   0.046875 -1.192975  0.038959\n",
      "3   MISSING   14     8    6    0.018957   0.031250 -0.499828  0.006144\n",
      "6     300.0   13     8    5    0.018957   0.026042 -0.317506  0.002249\n",
      "4     180.0   44    29   15    0.068720   0.078125 -0.128264  0.001206\n",
      "1     120.0    3     3    0    0.007109   0.000000  0.000000  0.000000\n",
      "5      60.0    2     2    0    0.004739   0.000000  0.000000  0.000000\n",
      "8      36.0    2     0    2    0.000000   0.010417  0.000000 -0.000000\n",
      "10     12.0    1     1    0    0.002370   0.000000  0.000000  0.000000\n",
      "0     360.0  512   359  153    0.850711   0.796875  0.065375  0.003519\n",
      "2     240.0    4     3    1    0.007109   0.005208  0.311102  0.000591\n",
      "9      84.0    4     3    1    0.007109   0.005208  0.311102  0.000591\n",
      "IV score is : 0.05326088284972044\n",
      "\n",
      "    \n",
      "WoE and IV for credit_history:\n",
      "     Value  All  Good  Bad  Distr_Good  Distr_Bad       WoE        IV\n",
      "1       No   89     7   82    0.016588   0.427083 -3.248319  1.333421\n",
      "2  MISSING   50    37   13    0.087678   0.067708  0.258459  0.005161\n",
      "0      Yes  475   378   97    0.895735   0.505208  0.572673  0.223644\n",
      "IV score is : 1.5622260698645571\n",
      "\n",
      "    \n",
      "WoE and IV for property_type:\n",
      "       Value  All  Good  Bad  Distr_Good  Distr_Bad       WoE        IV\n",
      "1      Rural  179   110   69    0.260664   0.359375 -0.321136  0.031700\n",
      "0      Urban  202   133   69    0.315166   0.359375 -0.131267  0.005803\n",
      "2  Semiurban  233   179   54    0.424171   0.281250  0.410892  0.058725\n",
      "IV score is : 0.09622794669184243\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for col in df_train.columns:\n",
    "    if col == target: continue\n",
    "    woe, iv = calculate_woe_iv(df_train, col, target)\n",
    "    print(f'WoE and IV for {col}:')\n",
    "    values_names = woe['Value'].tolist()\n",
    "    values_vals = woe['WoE'].tolist()\n",
    "    values_to_replace = {k: v for k, v in zip(values_names, values_vals)}\n",
    "    if iv > 0.02:\n",
    "        df_train = df_train.replace({col: values_to_replace})\n",
    "    print(woe)\n",
    "    print(f'IV score is : {iv}')\n",
    "    print('''\n",
    "    ''')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}